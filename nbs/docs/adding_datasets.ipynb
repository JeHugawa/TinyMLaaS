{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cf5f574",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986aea40",
   "metadata": {},
   "source": [
    "The application stores datasets as `.tar.gz` files in the AWS S3 service, but when the application is ran locally they are stored in [localstack](https://localstack.cloud/) - a local S3 clone running in docker-compose with the app.\n",
    "\n",
    "Localstack is initially empty and the datasets must be compressed and uploaded there on startup. For this purpose we have 2 datasets at the root of the git repo: `data` and `data2`. They are uncompressed because they would otherwise be too large for git. \n",
    "\n",
    "Dataset directories should contain directories named `0` and `1` which contain the images by category. Currently there can only be 2 categories. The images should be in png or jpeg formats. Note that the `0` directory should contain a file called `1.png` (required by `prediction` in `nbs/training.ipynb`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cfe610",
   "metadata": {},
   "source": [
    "# Adding a new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fd5f75",
   "metadata": {},
   "source": [
    "To add a new dataset, you should create a new directory containing directories `1` and `0`, with your images placed in these directories.\n",
    "\n",
    "Then you need to add an entry for it in the `dataset.csv` file. The first row describes the format of the csv file. The location column should contain the path to the dataset directory.\n",
    "\n",
    "You also need to add the dataset's location to `nbs/aws_s3.ipynb` inside the `download_tar_file` function to get the code to compress the dataset and upload it to localstack when running the application locally.\n",
    "\n",
    "With the above 3 changes, your new dataset should be usable in the web app.\n",
    "\n",
    "*Note that a couple of image paths are also hardcoded in `pages/tests/data/test_data_page.robot`. So you should change them if you want to move the datasets elsewhere.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e4c91e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
