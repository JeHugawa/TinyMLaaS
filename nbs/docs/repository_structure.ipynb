{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repository structure description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of the repository will be written here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## tflm_hello_world_staging/arduino/\n",
    "The `arduino` folder contains all the files and resources needed for running the Arduino portion of the project.\n",
    "\n",
    "### arduino/template/\n",
    "The `template` folder holds the source code files for the Arduino project. It includes the following files:\n",
    "\n",
    "- `arduino_detection_responder.cpp`: Contains the implementation for the detection responder, which processes detected objects and reacts accordingly.\n",
    "\n",
    "- `arduino_image_provider.cpp`: Handles image acquisition from the image source, such as a camera or sensor, and provides the images to other components for processing.\n",
    "\n",
    "- `arduino_main.cpp`: The main entry point for the Arduino program. It initializes the necessary components and manages the main loop of the program.\n",
    "\n",
    "- `detection_responder.h`: Header file for the detection responder, containing the class definition and function prototypes.\n",
    "\n",
    "- `image_provider.h`: Header file for the image provider, containing the class definition and function prototypes.\n",
    "\n",
    "- `main_functions.h`: Contains the function prototypes for the main loop and other utility functions used throughout the program.\n",
    "\n",
    "- `model_settings.cpp`: Contains the implementation for the model settings, including parameters related to the machine learning model (if applicable) and other configurations.\n",
    "\n",
    "- `model_settings.h`: Header file for the model settings, containing the class definition and function prototypes.\n",
    "\n",
    "### arduino/Dockerfile\n",
    "The `Dockerfile` is used to create a Docker container for the Arduino environment. It defines the necessary components, such as the base image, libraries, and dependencies, required to build and run the Arduino code within the container.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build/\n",
    "The `build` folder contains a list of Python dependencies necessary for the project. These dependencies are related to image processing, web automation, and testing frameworks. The required packages are:\n",
    "\n",
    "- `Pillow==9.0.1`: Python Imaging Library (PIL) fork that adds image processing capabilities to the project.\n",
    "- `robotframework`: A generic open-source automation framework for acceptance testing, acceptance test-driven development (ATDD), and robotic process automation (RPA).\n",
    "- `robotframework-seleniumlibrary`: A web testing library for Robot Framework that utilizes Selenium to control web browsers.\n",
    "- `selenium`: A web testing library that allows you to write test scripts in Python to automate browser actions.\n",
    "- `pytest`: A testing framework that makes it easy to write simple and scalable test cases for Python code.\n",
    "- `pytest-cov`: A plugin for pytest that generates coverage reports for test suites.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## /data & /data2\n",
    "\n",
    "The folders called \"/data\" and \"/data2\" contain pictures that are used to train image recognition or object recognition models. Within these folders, there are subfolders labeled \"0\" and \"1\". The \"0\" subfolder contains images that are not the expected ones, while the \"1\" subfolder contains images of expected objects such as humans or cars.. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nbs/\n",
    "The `nbs` folder contains Jupyter notebooks, configuration files, and additional resources for the project. It is organized as follows:\n",
    "\n",
    "### nbs/docs/\n",
    "The `docs` folder contains teams briefs such as dailies,sprintplanning & other information.\n",
    "\n",
    "### nbs/tests/\n",
    "The `tests` folder contains test cases and test resources for the project.\n",
    "\n",
    "### Jupyter Notebooks\n",
    "The Jupyter notebooks in the `nbs` folder serve various purposes, such as core functionality, exporting, training, and more:\n",
    "\n",
    "- `00_core.ipynb`: contains the core functionality of the project, along with tests and examples. \n",
    "- `01_export.ipynb`: This notebook contains functions and classes related to creating test files from the main codebase. It includes functionality for generating imports and wrapping test functions for pytest and unittest compatibility.\n",
    "- `aws_s3.ipynb`: This module provides a class S3_Connector for accessing and manipulating files on AWS S3. It also supports localstack for testing purposes.\n",
    "- `compiling.ipynb`: Demonstrates the process of compiling code. Defines a set of functions for converting a TensorFlow model into a TensorFlow Lite (TFLite) model and then into a C array, which can be used in microcontrollers or other low-resource environments. The code also includes a function to plot the size difference between the original TFLite model and the quantized TFLite model. Here's a brief overview of each function:\n",
    "- `index.ipynb`: Repositorys readme will be update via this notebook.\n",
    "- `installing.ipynb`: Demonstrates code for building and uploading Docker images for device-specific installers. It includes the following components:\n",
    "- `observing.ipynb`: Demonstrates the process of observing or monitoring the project, such as tracking performance metrics.\n",
    "- `tcp_hello_observer.ipynb`: Demonstrates code to implement a TcpHelloObserver class that reads hello_world values over TCP. \n",
    "\n",
    "\n",
    "- `training.ipynb`: Contains the code and resources necessary for training machine learning models or other algorithms.\n",
    "\n",
    "### Configuration and Other Files\n",
    "- `nbdev.yml`: Configuration file for nbdev, a system that helps build libraries from Jupyter notebooks.\n",
    "- `_quarto.yml`: Configuration file for Quarto, a publishing system for scientific and technical documents.\n",
    "- `styles.css`: Contains custom CSS styles used in the Jupyter notebooks or generated documentation.\n",
    "-------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## /pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contains the following python files : 1_Device.py, 2_Data.py, 3_Model.py, 4_Training.py, 5_Compiling.py, 6_Installing.py, 7_Observing.py, 8_Documentation.py. And a subfolder that is called tests which contains ROBOTFRAMEWORK tests for each page.\n",
    "\n",
    "\n",
    "Pages contains the frontend code that utilized streamlit. Each of the files contain the pages frontend code. Such as 1_Device.py contains the apps device page frontend code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `1_Device.py`: allows users to register and manage TinyML devices for the TinyML-as-a-Service (TinyMLaaS) platform. Specifically, this page enables users to add, modify, delete, and select a registered device.\n",
    "* `2_Data.py`: The code allows the user to upload images to the selected dataset, store images to AWS S3, and delete images from the dataset. \n",
    "* `3_Model.py`: Defines the behavior of the \"Model\" tab of the Streamlit app. It contains functions for displaying and selecting available models for training, and for visualizing a selected model.\n",
    "* `4_Training.py`:The purpose of the tab is to train an image classifier on a custom dataset provided by the user.\n",
    "* `5_Compiling.py`:Defines the behavior of the \"Compiling\" tab. This tab allows the user to compile a trained machine learning model to the format used by TinyML devices.\n",
    "* `7_Installing.py`:Purpose of this tab is to install the compiled model on a selected TinyML device.\n",
    "* `8_Observing.py`:This tab is for observing predictions sent from the TinyML device. It allows the user to control the data visualization, observe the device output, view the model's performance, and control the device. Most of the features here place holders. \n",
    "* `9_Documentation.py`: This tab lets the user read the documentation on how to use each page. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## /relay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `/relay` folder contains a Flask server that serves as an intermediary between the user and the microcontroller devices, providing API routes for uploading compiled sketches and getting predictions from the devices. The folder consists of the following files:\n",
    "\n",
    "1. `instructions.md`: This file contains instructions on how to set up and run the relay server.\n",
    "\n",
    "2. `main.py`: This is the main Flask application script that provides two API routes for interacting with the devices, as well as utility functions for uploading compiled sketches to the devices.\n",
    "\n",
    "3. `observing.py`: This file contains code related to observing the microcontroller devices.\n",
    "\n",
    "### API Routes\n",
    "\n",
    "1. `/install`: A `POST` route for installing the compiled sketch to the device. The request must include the device type. The server checks if the device is supported and uploads the sketch to the device accordingly.\n",
    "\n",
    "2. `/prediction`: A `GET` route for obtaining the prediction from the device. The request must include the device type. The server reads the prediction from the device and returns it in a JSON format.\n",
    "\n",
    "### Utility Functions\n",
    "\n",
    "1. `upload()`: Uploads the compiled sketch in Docker for the Arduino Nano 33 BLE device.\n",
    "2. `upload_rpi()`: Uploads the compiled person detection UF2 file to the Raspberry Pi Pico device. The device must be in USB Mass Storage Mode.\n",
    "3. `get_device_port(device_name: str)`: Returns the device port as a string.\n",
    "\n",
    "To use the relay server, follow the instructions provided in the `instructions.md` file. The server allows users to interact with the microcontroller devices easily, enabling them to upload compiled sketches and obtain predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## /rpi-pico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raspberry Pi Pico\n",
    "\n",
    "The `/rpi-pico` folder contains the necessary files for building and compiling the person detection model for the Raspberry Pi Pico microcontroller. The folder consists of the following files and subfolders:\n",
    "\n",
    "1. `Dockerfile`: A Dockerfile to set up the environment and compile the model for the Raspberry Pi Pico.\n",
    "\n",
    "2. `/code`:\n",
    "    - `CMakeLists.txt`: A CMake configuration file that includes the necessary settings to build the project.\n",
    "    - `pico_sdk_import.cmake`: A CMake script that imports the Pico SDK and sets up the build environment.\n",
    "    - `/person_detection_screen`: A subfolder containing the person detection model files and source code for the Raspberry Pi Pico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## /tflm_hello_world/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This folder contains the actual Python files for various functionalities related to the project:\n",
    "\n",
    "1. **aws_s3.py**: Provides functions for interacting with Amazon S3, specifically for uploading and downloading files related to the project.\n",
    "2. **compiling.py**: Implements the model compilation process for different devices using Docker and other tools.\n",
    "3. **core.py**: Contains core functionality for the project, such as the person detection model and its preprocessing and postprocessing.\n",
    "4. **export.py**: Offers functions for exporting the model and other assets to various formats and platforms.\n",
    "5. **installing.py**: Describes the process of installing the compiled model on different devices, such as the Raspberry Pi Pico and the Arduino Nano 33 BLE.\n",
    "6. **_modidx.py**: A module index file generated by the project's build system.\n",
    "7. **observing.py**: Implements functions for reading and processing the output of the person detection model on the target devices.\n",
    "8. **tcp_hello_observer.py**: Contains a class for reading hello_world values over a TCP connection.\n",
    "9. **training.py**: Provides functions related to the training and evaluation of the person detection model.\n",
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## /x86_simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This folder contains the Python file for simulating the person detection model on x86 architectures:\n",
    "\n",
    "1. **inference.py**: A script for running the person detection model on a single image using TensorFlow Lite. The script loads an image and the TFLite model, preprocesses the image, performs inference, and prints the classification result along with the confidence score.\n",
    "------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files in the root\n",
    "-------------------------------------------------------------------------------------------\n",
    "\n",
    "### app.robot File Documentation\n",
    "\n",
    "\n",
    "1. **Settings**: The settings section includes importing the SeleniumLibrary and Process libraries and defining Suite Setup and Suite Teardown actions.\n",
    "\n",
    "2. **Keywords**: The keywords section defines custom keywords for starting and stopping the webserver.\n",
    "\n",
    "3. **Variables**: The variables section defines the URL and browser for testing purposes.\n",
    "\n",
    "4. **Test Cases**: The test cases section includes the following test cases:\n",
    "   1. **test 1**: Tests the navigation to the main page and interaction with the \"Device\" link.\n",
    "   2. **test 2**: Tests the navigation to the \"Device\" page.\n",
    "   3. **test 3**: Tests the navigation to the \"Data\" page.\n",
    "   4. **test 4**: Tests the navigation to the \"Model\" page.\n",
    "   5. **test 5**: Tests the navigation to the \"Training\" page.\n",
    "   6. **test 6**: Tests the navigation to the \"Compiling\" page.\n",
    "   7. **test 7**: Tests the navigation to the \"Installing\" page.\n",
    "   8. **test 8**: Tests the navigation to the \"Observing\" page.\n",
    "-------------------------------------------------------------------------------------------\n",
    "### docker-compose.yml \n",
    "\n",
    "This file is a Docker Compose configuration file that describes how the containers for the TinyML as-a-Service project are built, run, and connected. It defines the following services:\n",
    "\n",
    "1. **frontend**: The frontend service builds and runs the web application using the `frontend.Dockerfile`. It maps the ports 50007 and 8501 for external access and sets the environment variable `USE_LOCALSTACK` to 1. It also runs the container in privileged mode and mounts the Docker socket as a volume.\n",
    "\n",
    "2. **localstack**: The localstack service uses the official LocalStack image to provide a local AWS-like environment. It maps ports 4566 and the range 4510-4559 for external access. The environment variables `DEBUG`, `LAMBDA_EXECUTOR`, and `DOCKER_HOST` are set, and SSL certificate downloading is skipped. The Docker socket is mounted as a volume.\n",
    "\n",
    "Note: The `hello_world` service is commented out in the current configuration file, but it can be added in the future for more functionality.\n",
    "\n",
    "-------------------------------------------------------------------------------------------\n",
    "### frontend.Dockerfile\n",
    "\n",
    "This Dockerfile is used to build the frontend container for the TinyML as-a-Service project. The steps in this Dockerfile are as follows:\n",
    "\n",
    "1. Use the `python:3.9.0-slim-buster` base image.\n",
    "2. Update the package lists and install the necessary dependencies: `curl`, `libportaudio2`, `libusb-1.0`, `graphviz`, `python3-opencv`, and `xxd`.\n",
    "3. Set the working directory to `/app`.\n",
    "4. Copy the `data` directory from the host to the `/data/` directory in the container.\n",
    "5. Copy the `requirements.txt` file from the host to the container.\n",
    "6. Install the Python packages listed in `requirements.txt` using `pip3`.\n",
    "7. Download and install Docker by running the Docker installation script.\n",
    "8. Create a `temp` directory.\n",
    "9. Copy all the remaining files from the host to the container.\n",
    "10. Set the container's entrypoint command to run the TinyMLaaS application using `python3`, `coverage`, and `streamlit`.\n",
    "\n",
    "This Dockerfile ensures that all necessary dependencies and files are in place to run the TinyML as-a-Service frontend in a containerized environment.\n",
    "\n",
    "-------------------------------------------------------------------------------------------\n",
    "### inference.Dockerfile:\n",
    "* The inference.Dockerfile creates a Docker image containing a Python application that performs inference on an image using a pre-trained TensorFlow Lite model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
