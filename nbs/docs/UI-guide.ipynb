{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3676b4c1-782e-4fe4-86fd-5f595bffa44a",
   "metadata": {},
   "source": [
    "# UI design guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515d92de-2034-4a03-8cfb-f2be14ba316e",
   "metadata": {},
   "source": [
    "In principle, we won't do more than what [Streamlit](https://streamlit.io/) provides now.\n",
    "We have chosen Streamlit because of its good trade-off balance between easiness of UI implementation and its relatively good limitted expressiveness of UI parts.\n",
    "If we really want ultimate fancy UI, we should have gone with React with more effort.\n",
    "That's not what we want, at least, for now for this `TinyML as-a-Service` (TinyMLaaS)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71232dc-89eb-4d41-a173-30c75b76f2c0",
   "metadata": {},
   "source": [
    "This platform, TinyMLaaS, is for **Seamless TinyML lifecycle management**. This include the following 7 stages:\n",
    "\n",
    "1. `Device` registration\n",
    "2. `Data` registration\n",
    "3. `Model` registration\n",
    "4. `Training` ML model with Dataset\n",
    "5. `Compiling` trained ML into TinyML\n",
    "6. `Installing` OS image via Software Over The Air update (SOTA)\n",
    "7. `Observing` ML predictions\n",
    "\n",
    "Basically the above 7 operations should flow in this order from the top to the bottom. These 7 steps are always listed in side bar. Users can alwasy see which step he's working on now from this side-bar.  Each item listed in the side-bar should have some indicator icon of `done` or `to-be-done` at the start of each item line to show which steps have already been done or not to users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8595857a-3ceb-4cb0-85fc-ae43afd79601",
   "metadata": {},
   "source": [
    "**TinyMLaaS**\n",
    "\n",
    "Apart from the above 7 stages in the side-bar, there is a front page of this WebApp, shown at opening. We could consider this front page as `Dash board` to summarize what this TinyMLaaS accomodates (i.e. Overview). This `Dash board` has the following 3 panels:\n",
    "\n",
    "-  Alart panel: This panel should list some alart of low-battery devices, poor connectivity devices, and unresponsive devices to prompt users to take further actions respectively.\n",
    "\n",
    "- Device location map: This panel should show a location map of registered IoT devices on the top of page.\n",
    "  This device location map should be timelapse.\n",
    "  User could see how those devices have moved for last 24 hours, for example.\n",
    " \n",
    "- Some statisical data: This panel should show the major statistical data at realtime, # of registered devices, # of connected ones, # of data transaction, total hours of whole connected devices, for example.\n",
    "\n",
    "This front page is a `Dash board` so that it shouldn't include any **control** operations over the system (i.e. action). These control operations should be done via the appropriate tab in the side-bar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4975779c-0e94-46bd-8b96-4c4a7f116280",
   "metadata": {},
   "source": [
    "**Device**\n",
    "\n",
    "-   Add / Remove a device: This `Device` tab allows users to add a new device to the\n",
    "    platform and also remove it if not needed. Users would need to provide some basic information about\n",
    "    the device, such as its name, type, ip address, and location.\n",
    "    Once a device is connected, this tab should show some statistical data, the last time connected, how much data sent, e.t.c.\n",
    "    \n",
    "-   Update device: This tab allows users to update the information for a\n",
    "    device that is already connected to the platform. Users would need\n",
    "    to select the device they want to update from a device list and then provide the new\n",
    "    information.\n",
    "    \n",
    "This `Device` tab should have only device related information. It shouldn't have associated with any ML related entities (`Model` and `Installing`) yet. This should be done in `Installing` tab later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011dd660-a100-4714-a063-82e000e59e7d",
   "metadata": {},
   "source": [
    "**Data**\n",
    "\n",
    "There are 2 type of data sources here. One for static dataset (file archives) and another for realtime incoming sensor data.\n",
    "\n",
    "-   Data source selection: This tab allows users to select a data source\n",
    "    for Training. The available data sources will depend on the\n",
    "    device that was selected in the previous step. Users might be able\n",
    "    to choose from options such as sensors, cameras, or pre-recorded\n",
    "    datasets. In the case of collecting data from sensor, we need some UI to check image data and put label on it before storing in storage.\n",
    "    \n",
    "- Both dataset should be stored in remote storage as an compressed archive. This dataset would be used at Training. Once it's stored in storage, we'd deal with different data sourcesin the unified manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b871e5f-6f0f-44d1-8e90-677f2ce4c262",
   "metadata": {},
   "source": [
    "**Model**\n",
    "\n",
    "-   Model selection: This tab allows users to select an ML model for dataset. Users might be able to choose from\n",
    "    a list of pre-trained models or upload their own custom models.\n",
    "-   Model versions: This tab allows users to select a specific version\n",
    "    of the selected ML model. Users might be able to choose from\n",
    "    different versions that have been trained on different datasets or\n",
    "    with different parameters.\n",
    "-   Other ML model parameters (if any): This tab allows users to\n",
    "    configure any additional parameters for the ML model, such as\n",
    "    hyperparameters or preprocessing steps. These parameters will depend\n",
    "    on the specific ML model that was selected.\n",
    "-   Compatibility check with data source: This tab checks\n",
    "    whether the selected ML model is compatible with the selected data\n",
    "    source. If there are any compatibility issues, users will\n",
    "    need to adjust their selections before proceeding.\n",
    "    \n",
    "    \n",
    "`Model` shouldn't depend on `Device`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cae4f6-aca5-4406-9492-49c2dbab24d8",
   "metadata": {},
   "source": [
    "**Training**\n",
    "\n",
    "At `Training`, User should associate `Model` with `Data` for the 1st time, but `Training` should be done independently from `Device`.\n",
    "\n",
    "-   Training settings: This tab allows users to configure the settings\n",
    "    for the ML model training process. Users might be able to choose\n",
    "    from options such as the number of epochs, batch size, or learning\n",
    "    rate.\n",
    "-   Training process: This tab displays information about the training\n",
    "    process for the selected ML model. Users might be able to view\n",
    "    metrics such as accuracy, loss, or validation error. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19f6320-401f-4110-a670-ce02f701f2d8",
   "metadata": {},
   "source": [
    "**Compiling**\n",
    "\n",
    "This is ML compilation, independent from CPU arch and device spec.\n",
    "\n",
    "-   Compilation settings: This tab allows users to configure the\n",
    "    settings for compiling the ML model, independept of devices.\n",
    "-   Compilation process: This tab displays information about the\n",
    "    compilation process for the selected ML model. Users might be able\n",
    "    to view metrics such as compilation time, model size, etc.\n",
    "-   Model validation: This tab validates the model after compilation.\n",
    "    Users might be able to see metrics such as accuracy, latency, or\n",
    "    power consumption, at x86 simulation. They might also be able to compare the\n",
    "    performance of different models or configurations.\n",
    "-   Model packaging: This tab packages the compiled model in a format\n",
    "    that can be installed on the target device.\n",
    "-   Packaging status: This tab displays the status of the packaging\n",
    "    process. Users might be able to see progress bars, error messages,\n",
    "    or other information about the packaging. This tab can be useful for\n",
    "    monitoring the packaging process and resolving any issues that might\n",
    "    arise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cf5032-ca22-42bb-8250-967173297eff",
   "metadata": {},
   "source": [
    "**Installing**\n",
    "\n",
    "This is the 1st place to generate an installable OS image for a specific device. This image sholud include TinyML model in it, to be used by some app specific logic running on the device. There's been no arch dependency in any of previous phases but here it's associated. And the output OS image should be installed on the dvice via Software Over The Air update (SOTA).\n",
    "\n",
    "-   Installation settings: It lists a summary of all the previous\n",
    "    selected steps.\n",
    "-   Installation status: This tab displays the status of the\n",
    "    installation process. Users might be able to see progress bars,\n",
    "    error messages, or other information about the installation. This\n",
    "    tab can be useful for monitoring the installation process and\n",
    "    resolving any issues that might arise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0e739f-f32e-4e4e-a1c5-1077881a40cd",
   "metadata": {},
   "source": [
    "**Observing**\n",
    "\n",
    "-   Device output: It displays the output of the ML model running on the\n",
    "    selected device. Users might be able to see real-time data coming\n",
    "    from sensors or other sources, as well as the predictions made by\n",
    "    the ML model.\n",
    "-   Data visualization: It allows users to visualize the data being\n",
    "    generated by the device and the ML model. Users might be able to see\n",
    "    graphs, charts, or other visualizations of the data over time.\n",
    "-   Model performance: It displays information about the performance of\n",
    "    the ML model running on the device. Users might be able to see\n",
    "    metrics such as accuracy, latency, or power consumption. They might\n",
    "    also be able to compare the performance of different models or\n",
    "    configurations.\n",
    "-   Device control: It allows users to control the device and the ML\n",
    "    model running on it. Users might be able to start or stop data\n",
    "    collection, adjust the model parameters, or send commands to the\n",
    "    device. This tab can be useful for debugging or fine-tuning the ML\n",
    "    model in real-time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
