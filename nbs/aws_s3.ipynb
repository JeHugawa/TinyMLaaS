{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9b6681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp aws_s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ceb9275a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import boto3\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import os\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fcb71d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class S3_Connector:\n",
    "    \"Class for accessing files on S3. If the environment variable USE_LOCALSTACK is set to 1, localstack will be used instead of AWS.\"\n",
    "    TEST_URL = \"http://localstack:4566\"\n",
    "    \n",
    "    def __init__(self, bucket_name:str):\n",
    "        if os.getenv(\"USE_LOCALSTACK\") == \"1\":\n",
    "            self.s3 = boto3.client('s3', endpoint_url=S3_Connector.TEST_URL, aws_access_key_id=\"\", aws_secret_access_key=\"\")\n",
    "            self.s3_resource = boto3.resource('s3', endpoint_url=S3_Connector.TEST_URL, aws_access_key_id=\"\", aws_secret_access_key=\"\")\n",
    "            self.s3.create_bucket(Bucket=bucket_name)\n",
    "        else:\n",
    "            self.s3 = boto3.client('s3')\n",
    "            self.s3_resource = boto3.resource('s3')\n",
    "        self.bucket_name = bucket_name\n",
    "        self.s3_bucket = self.s3_resource.Bucket(self.bucket_name)\n",
    "\n",
    "    def move(self, dir_old:str, dir_new:str, file_name:str):\n",
    "        \" Moves an object to other directory\"\n",
    "\n",
    "        old_destination = f'{dir_old}/{file_name}'\n",
    "        new_destination = f'{dir_new}/{file_name}'\n",
    "        copy_source = {\n",
    "                        'Bucket': self.bucket_name,\n",
    "                        'Key': old_destination}\n",
    "        self.s3.copy_object(CopySource=copy_source, Bucket=self.bucket_name, Key=new_destination)\n",
    "        self.s3.delete_object(Bucket=self.bucket_name, Key=old_destination)\n",
    "\n",
    "        return True\n",
    "\n",
    "    def upload_img(self, img, dir:str, file_name:str, pil_image = False):\n",
    "        \" Uploads an image to specified directory. `img` is a file-like object, unless pil_image is True in which case it's a Pillow Image.\"\n",
    "        if pil_image:\n",
    "            buffer = BytesIO()\n",
    "            img.save(buffer, format=\"PNG\")\n",
    "            buffer.seek(0)\n",
    "            self.s3.upload_fileobj(buffer, self.bucket_name, f'{dir}/{file_name}')\n",
    "        else:\n",
    "            self.s3.upload_fileobj(img, self.bucket_name, f'{dir}/{file_name}')\n",
    "\n",
    "        return True\n",
    "\n",
    "    def read_images(self, dir : str):\n",
    "        \" Reads images from S3 directory `dir`\"\n",
    "\n",
    "        imgs = []\n",
    "        for img in self.s3_bucket.objects.filter(Prefix=dir):\n",
    "            file_path = img.key\n",
    "            if file_path.endswith(('jpg', 'png')):\n",
    "                image_data = BytesIO()\n",
    "                self.s3_bucket.download_fileobj(img.key, image_data)\n",
    "                image = Image.open(image_data)\n",
    "\n",
    "                # Insert file name\n",
    "                image.filename = img.key.split('/')[-1]\n",
    "                imgs.append(image)\n",
    "        \n",
    "        return imgs\n",
    "    \n",
    "    def count_objects(self, dir : str):\n",
    "        \" Counts objects in S3 directory `dir`\"\n",
    "\n",
    "        count_objects = self.s3_bucket.objects.filter(Prefix=dir)\n",
    "\n",
    "        if os.getenv(\"USE_LOCALSTACK\") == \"1\":\n",
    "            return len(list(count_objects)) -1\n",
    "        else:\n",
    "            return len(list(count_objects))\n",
    "    \n",
    "    def upload_tar_file(self, tar_file : str):\n",
    "        \" Upload tar.gz file to S3 directory\"\n",
    "\n",
    "        with open(f'{tar_file}', 'rb') as tar:\n",
    "            self.s3.upload_fileobj(tar, self.bucket_name, tar_file)\n",
    "    \n",
    "    def download_tar_file(self, tar_file: str):\n",
    "        \" Upload tar.gz file to S3 directory\"        \n",
    "\n",
    "        tmp_dir = f'temp/{tar_file}'\n",
    "        extract_dir = f'temp/'\n",
    "\n",
    "        if os.getenv(\"USE_LOCALSTACK\") == \"1\":\n",
    "            self.create_tar_archive('data.tar.gz', 'data')\n",
    "            self.upload_tar_file('data.tar.gz')\n",
    "            self.create_tar_archive('data2.tar.gz', 'data2')\n",
    "            self.upload_tar_file('data2.tar.gz')\n",
    "            self.s3.download_file(self.bucket_name, tar_file, tmp_dir)\n",
    "        else:\n",
    "            self.s3.download_file(self.bucket_name, tar_file, tmp_dir)\n",
    "\n",
    "        with tarfile.open(tmp_dir, 'r:gz') as tar:\n",
    "            tar.extractall(path=extract_dir)\n",
    "    \n",
    "    def create_tar_archive(self, output_filename, dataset):\n",
    "        \"\"\"Creates a tar.gz archive from a folder.\"\"\"\n",
    "        with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "            tar.add(dataset, arcname=os.path.basename(dataset))\n",
    "\n",
    "\n",
    "\n",
    "BUCKET_NAME = 'tflmhelloworldbucket'\n",
    "s3_conn = S3_Connector(BUCKET_NAME)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6989b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0e39d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### S3_Connector.move\n",
       "\n",
       ">      S3_Connector.move (dir_old:str, dir_new:str, file_name:str)\n",
       "\n",
       "Moves an object to other directory"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### S3_Connector.move\n",
       "\n",
       ">      S3_Connector.move (dir_old:str, dir_new:str, file_name:str)\n",
       "\n",
       "Moves an object to other directory"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(S3_Connector.move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "874743d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### S3_Connector.upload_img\n",
       "\n",
       ">      S3_Connector.upload_img (img, dir:str, file_name:str, pil_image=False)\n",
       "\n",
       "Uploads an image to specified directory. `img` is a file-like object, unless pil_image is True in which case it's a Pillow Image."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### S3_Connector.upload_img\n",
       "\n",
       ">      S3_Connector.upload_img (img, dir:str, file_name:str, pil_image=False)\n",
       "\n",
       "Uploads an image to specified directory. `img` is a file-like object, unless pil_image is True in which case it's a Pillow Image."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(S3_Connector.upload_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dff8943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### S3_Connector.read_images\n",
       "\n",
       ">      S3_Connector.read_images (dir:str)\n",
       "\n",
       "Reads images from S3 directory `dir`"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### S3_Connector.read_images\n",
       "\n",
       ">      S3_Connector.read_images (dir:str)\n",
       "\n",
       "Reads images from S3 directory `dir`"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(S3_Connector.read_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7de5f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### S3_Connector.count_objects\n",
       "\n",
       ">      S3_Connector.count_objects (dir:str)\n",
       "\n",
       "Counts objects in S3 directory `dir`"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### S3_Connector.count_objects\n",
       "\n",
       ">      S3_Connector.count_objects (dir:str)\n",
       "\n",
       "Counts objects in S3 directory `dir`"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(S3_Connector.count_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f814119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### S3_Connector.delete_objects\n",
       "\n",
       ">      S3_Connector.delete_objects (dir:str)\n",
       "\n",
       "Delete objects in S3 directory `dir`"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### S3_Connector.delete_objects\n",
       "\n",
       ">      S3_Connector.delete_objects (dir:str)\n",
       "\n",
       "Delete objects in S3 directory `dir`"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(S3_Connector.delete_objects)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
